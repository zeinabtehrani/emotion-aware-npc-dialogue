# -*- coding: utf-8 -*-
"""Southeast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DZgBchfce-kQ3v06oWN_nIwLNFTCogUU
"""

!pip install -q transformers torch

import time
from transformers import pipeline

class EmotionDetector:
    """
    Lightweight emotion detection module using a pretrained transformer.
    No training or fine-tuning is performed.
    """

    def __init__(self, model_name="j-hartmann/emotion-english-distilroberta-base"):
        self.model_name = model_name
        self.classifier = pipeline(
            task="text-classification",
            model=model_name,
            return_all_scores=True
        )

    def predict(self, text: str):
        """
        Predict emotion for an English input sentence.

        Returns:
            dict with keys:
            - label (str)
            - confidence (float)
            - latency (float, seconds)
            - all_scores (list of dicts)
        """
        start_time = time.time()
        scores = self.classifier(text)[0]
        latency = time.time() - start_time

        top_prediction = max(scores, key=lambda x: x["score"])

        return {
            "label": top_prediction["label"],
            "confidence": float(top_prediction["score"]),
            "latency": latency,
            "all_scores": scores
        }

# Sanity check
detector = EmotionDetector()

test_sentences = [
    "I feel completely exhausted and overwhelmed.",
    "I am so proud of what I achieved today!",
    "Nothing makes sense anymore.",
    "I am furious about what just happened."
]

for sentence in test_sentences:
    result = detector.predict(sentence)
    print(f"Input: {sentence}")
    print(f"Prediction: {result['label']} | Confidence: {result['confidence']:.3f} | Latency: {result['latency']:.4f}s")
    print("-" * 60)

# PART 2 — Input Dataset Design

# This dataset is manually constructed to allow
# controlled evaluation of emotion detection behavior.

dataset = [

    # ------------------
    # ENGLISH — LITERAL
    # ------------------
    {
        "text": "I feel completely exhausted and overwhelmed.",
        "emotion": "sadness",
        "language": "English",
        "type": "literal"
    },
    {
        "text": "I am so proud of what I achieved today.",
        "emotion": "joy",
        "language": "English",
        "type": "literal"
    },
    {
        "text": "I am furious about what just happened.",
        "emotion": "anger",
        "language": "English",
        "type": "literal"
    },

    # ------------------
    # ENGLISH — IDIOMS
    # ------------------
    {
        "text": "I've hit rock bottom.",
        "emotion": "sadness",
        "language": "English",
        "type": "idiom"
    },

    # ------------------
    # PERSIAN — LITERAL
    # ------------------
    {
        "text": "دیگه از همه چی خسته شدم.",
        "emotion": "sadness",
        "language": "Persian",
        "type": "literal"
    },

    # ------------------
    # PERSIAN — IDIOMS
    # ------------------
    {
        "text": "دیگه آب خوش از گلومم پایین نمی‌ره.",
        "emotion": "sadness",
        "language": "Persian",
        "type": "idiom"
    },

    # ------------------
    # FRENCH — LITERAL
    # ------------------
    {
        "text": "Je suis très fatigué de tout.",
        "emotion": "sadness",
        "language": "French",
        "type": "literal"
    },

    # ------------------
    # FRENCH — IDIOMS
    # ------------------
    {
        "text": "J’ai le moral dans les chaussettes.",
        "emotion": "sadness",
        "language": "French",
        "type": "idiom"
    },

    # ------------------
    # ARABIC — LITERAL
    # ------------------
    {
        "text": "أنا متعب جدًا من كل شيء.",
        "emotion": "sadness",
        "language": "Arabic",
        "type": "literal"
    },

    # ------------------
    # ARABIC — IDIOMS
    # ------------------
    {
        "text": "ضاق صدري وما عدت أتحمل.",
        "emotion": "sadness",
        "language": "Arabic",
        "type": "idiom"
    }
]

# Inspect dataset
for sample in dataset:
    print(sample)

!pip install deep_translator
# PART 4 — Translation Pipeline

import time
from deep_translator import GoogleTranslator

class Translator:
    """
    Translation module for converting non-English text to English.
    Measures translation latency for system-level analysis.
    """

    def __init__(self, target_language="en"):
        self.target_language = target_language

    def translate(self, text: str, source_language: str):
        """
        Translate input text to English if needed.

        Returns:
            dict with keys:
            - original_text
            - translated_text
            - latency
        """
        if source_language == "English":
            return {
                "original_text": text,
                "translated_text": text,
                "latency": 0.0
            }

        start_time = time.time()
        translated = GoogleTranslator(
            source="auto",
            target=self.target_language
        ).translate(text)
        latency = time.time() - start_time

        return {
            "original_text": text,
            "translated_text": translated,
            "latency": latency
        }

# Sanity check for translation module

translator = Translator()

test_cases = [
    ("Je suis très fatigué de tout.", "French"),
    ("دیگه از همه چی خسته شدم.", "Persian"),
    ("ضاق صدري وما عدت أتحمل.", "Arabic"),
    ("I feel exhausted.", "English")
]

for text, lang in test_cases:
    result = translator.translate(text, lang)
    print(f"Original ({lang}): {result['original_text']}")
    print(f"Translated: {result['translated_text']}")
    print(f"Latency: {result['latency']:.3f}s")
    print("-" * 60)

# PART 5 — Response Engine

class ResponseEngine:
    """
    Rule-based response selector for emotion-aware systems.
    No learning is performed.
    """

    def __init__(self):
        self.response_map = {
            "joy": "That’s wonderful to hear. You should be proud of yourself.",
            "sadness": "I’m here with you. You’re not alone in feeling this way.",
            "anger": "It sounds like you’re feeling unheard. Your feelings matter.",
            "fear": "It’s okay to feel scared. You don’t have to face this alone.",
            "surprise": "That sounds unexpected. Take a moment to breathe.",
            "disgust": "That sounds really uncomfortable. I’m here with you.",
            "neutral": "I’m listening. Tell me more."
        }

    def respond(self, emotion_label: str):
        """
        Return a supportive response based on emotion label.
        """
        return self.response_map.get(
            emotion_label,
            "I’m here with you."
        )

# Sanity check for response engine

engine = ResponseEngine()

test_emotions = [
    "sadness",
    "joy",
    "anger",
    "fear",
    "surprise",
    "disgust",
    "neutral"
]

for emotion in test_emotions:
    print(f"Emotion: {emotion}")
    print(f"Response: {engine.respond(emotion)}")
    print("-" * 60)

# PART 6 — System Integration & Evaluation

import pandas as pd

# Instantiate components
detector = EmotionDetector()
translator = Translator()
responder = ResponseEngine()

results = []

for sample in dataset:
    text = sample["text"]
    intended_emotion = sample["emotion"]
    language = sample["language"]
    expr_type = sample["type"]

    # Step 1: Translation
    translation_result = translator.translate(text, language)
    translated_text = translation_result["translated_text"]
    translation_latency = translation_result["latency"]

    # Step 2: Emotion detection
    prediction = detector.predict(translated_text)

    predicted_emotion = prediction["label"]
    confidence = prediction["confidence"]
    model_latency = prediction["latency"]

    # Step 3: Response selection
    response = responder.respond(predicted_emotion)

    # Step 4: Log everything
    results.append({
        "original_text": text,
        "translated_text": translated_text,
        "language": language,
        "type": expr_type,
        "intended_emotion": intended_emotion,
        "predicted_emotion": predicted_emotion,
        "confidence": confidence,
        "correct": predicted_emotion == intended_emotion,
        "translation_latency": translation_latency,
        "model_latency": model_latency,
        "total_latency": translation_latency + model_latency,
        "response": response
    })

# Convert to DataFrame
df_results = pd.DataFrame(results)
df_results

# Overall accuracy
overall_accuracy = df_results["correct"].mean()

# Accuracy by language
accuracy_by_language = df_results.groupby("language")["correct"].mean()

# Accuracy by expression type
accuracy_by_type = df_results.groupby("type")["correct"].mean()

# Latency stats
latency_stats = df_results[["translation_latency", "model_latency", "total_latency"]].mean()

print("Overall Accuracy:", overall_accuracy)
print("\nAccuracy by Language:")
print(accuracy_by_language)
print("\nAccuracy by Expression Type:")
print(accuracy_by_type)
print("\nAverage Latency (seconds):")
print(latency_stats)

# PART 7 — Error & Failure Analysis

# Misclassified samples
errors_df = df_results[df_results["correct"] == False]

errors_df

# Error count by language
error_by_language = errors_df.groupby("language").size()

# Error count by expression type
error_by_type = errors_df.groupby("type").size()

print("Errors by Language:")
print(error_by_language)

print("\nErrors by Expression Type:")
print(error_by_type)

# Detailed inspection of each error
for idx, row in errors_df.iterrows():
    print("Original Text:", row["original_text"])
    print("Translated Text:", row["translated_text"])
    print("Language:", row["language"])
    print("Expression Type:", row["type"])
    print("Intended Emotion:", row["intended_emotion"])
    print("Predicted Emotion:", row["predicted_emotion"])
    print("Confidence:", f"{row['confidence']:.3f}")
    print("-" * 70)

# FIGURE 1 — Accuracy by Language

import matplotlib.pyplot as plt

accuracy_by_language.plot(kind="bar")
plt.title("Emotion Detection Accuracy by Language")
plt.xlabel("Language")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.tight_layout()
plt.show()

# FIGURE 2 — Accuracy by Expression Type

import matplotlib.pyplot as plt

accuracy_by_type.plot(kind="bar")
plt.title("Emotion Detection Accuracy by Expression Type")
plt.xlabel("Expression Type")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.tight_layout()
plt.show()

# FIGURE 3 — Average Latency Breakdown

import matplotlib.pyplot as plt

latency_stats.plot(kind="bar")
plt.title("Average Latency Breakdown")
plt.xlabel("Pipeline Component")
plt.ylabel("Latency (seconds)")
plt.ylim(0, latency_stats.max() * 1.2)
plt.tight_layout()
plt.show()

# TABLE 1 — Reduced IEEE-Style Table

table1 = df_results[[
    "language",
    "type",
    "intended_emotion",
    "predicted_emotion",
    "confidence"
]]

table1

from matplotlib import pyplot as plt
table1['confidence'].plot(kind='hist', bins=20, title='confidence')
plt.gca().spines[['top', 'right',]].set_visible(False)